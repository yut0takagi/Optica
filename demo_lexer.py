#!/usr/bin/env python3
"""
Optica Lexer ãƒ‡ãƒ¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Lexerã®å‹•ä½œã‚’ç¢ºèªã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã™ã€‚
"""

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))

from optica.lexer import tokenize, LexerError
from optica.tokens import TokenType


def demo_basic():
    """åŸºæœ¬çš„ãªãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã®ãƒ‡ãƒ¢"""
    print("=" * 60)
    print("ğŸ“ Optica Lexer ãƒ‡ãƒ¢")
    print("=" * 60)

    # ã‚·ãƒ³ãƒ—ãƒ«ãªä¾‹
    examples = [
        ('é›†åˆå®šç¾©', 'set STUDENTS = {"S1", "S2", "S3"}'),
        ('ç¯„å›²é›†åˆ', 'set SLOTS = 1..5'),
        ('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿', 'param cost[ITEMS] real'),
        ('å¤‰æ•°å®šç¾©', 'var x[STUDENTS, SLOTS] binary'),
        ('ç›®çš„é–¢æ•°', 'maximize profit:\n    sum(i in ITEMS) price[i] * x[i]'),
        ('åˆ¶ç´„', 'forall s in STUDENTS, k in SLOTS:\n    x[s,k] <= 1'),
    ]

    for name, source in examples:
        print(f"\nğŸ”¹ {name}")
        print(f"   å…¥åŠ›: {source!r}")
        print("   ãƒˆãƒ¼ã‚¯ãƒ³:")

        try:
            tokens = tokenize(source)
            for token in tokens:
                if token.type in (TokenType.NEWLINE, TokenType.INDENT, TokenType.DEDENT):
                    print(f"      [{token.type.name}]")
                elif token.type == TokenType.EOF:
                    print(f"      [{token.type.name}]")
                else:
                    print(f"      {token.type.name}: {token.value!r}")
        except LexerError as e:
            print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")


def demo_file(filepath: str):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã™ã‚‹ãƒ‡ãƒ¢"""
    print("\n" + "=" * 60)
    print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–: {filepath}")
    print("=" * 60)

    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            source = f.read()

        tokens = tokenize(source)

        # çµ±è¨ˆæƒ…å ±
        type_counts: dict[str, int] = {}
        for token in tokens:
            type_name = token.type.name
            type_counts[type_name] = type_counts.get(type_name, 0) + 1

        print(f"\nğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³çµ±è¨ˆ:")
        print(f"   ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {len(tokens)}")
        print("\n   ãƒˆãƒ¼ã‚¯ãƒ³ã‚¿ã‚¤ãƒ—åˆ¥:")
        for type_name, count in sorted(type_counts.items(), key=lambda x: -x[1]):
            print(f"      {type_name}: {count}")

        # é‡è¦ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¡¨ç¤º
        print("\nğŸ” é‡è¦ãªãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆæœ€åˆã®50å€‹ï¼‰:")
        count = 0
        for token in tokens:
            if token.type not in (TokenType.NEWLINE, TokenType.INDENT, TokenType.DEDENT, TokenType.EOF):
                print(f"   L{token.line:2}:{token.column:2} {token.type.name:12} {token.value!r}")
                count += 1
                if count >= 50:
                    print("   ... (çœç•¥)")
                    break

    except FileNotFoundError:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
    except LexerError as e:
        print(f"âŒ å­—å¥è§£æã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    demo_basic()

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
    example_file = Path(__file__).parent / "examples" / "juku_timetabling.optica"
    if example_file.exists():
        demo_file(str(example_file))

    print("\n" + "=" * 60)
    print("âœ… Lexer ãƒ‡ãƒ¢å®Œäº†ï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()

